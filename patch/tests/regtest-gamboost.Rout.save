
R version 2.10.0 (2009-10-26)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> require("mboost")
Loading required package: mboost
Loading required package: modeltools
Loading required package: stats4
Loading required package: party
Loading required package: survival
Loading required package: splines
Loading required package: grid
Loading required package: coin
Loading required package: mvtnorm
Loading required package: zoo

Attaching package: 'zoo'


	The following object(s) are masked from package:base :

	 as.Date.numeric 

Loading required package: sandwich
Loading required package: strucchange
Loading required package: vcd
Loading required package: MASS
Loading required package: colorspace
> 
> set.seed(290875)
> 
> ### for boosting hat matrix checks
> fm <- GaussReg()
> fm@offset <- function(y, w) 0
> 
> ### a simple two-dimensional example from `gamboost.Rd'
> data("cars")
> cars.gb <- gamboost(dist ~ speed, data = cars, df = 4, family = fm,
+                     control = boost_control(mstop = 50))
> cars.gb

	 Generalized Additive Models Fitted via Gradient Boosting

Call:
gamboost.formula(formula = dist ~ speed, data = cars, df = 4,     family = fm, control = boost_control(mstop = 50))


	 Squared Error (Regression) 

Loss function: (y - f)^2 
 

Number of boosting iterations: mstop = 50 
Step size:  0.1 
Offset:  0 

> aic <- AIC(cars.gb, method = "corrected")
> aic
[1] 6.625437
Optimal number of boosting iterations: 34 
Degrees of freedom (for mstop = 34): 5.056182 
> 
> ht <- hatvalues(cars.gb)
> 
> ### plot fit
> plot(dist ~ speed, data = cars)
> lines(cars$speed, predict(cars.gb[mstop(AIC(cars.gb))]), col = "red")
> lines(cars$speed, predict(smooth.spline(cars$speed, cars$dist), cars$speed)$y, 
+       col = "green")
> 
> #### check boosting hat matrix and subsetting / predict
> stopifnot(isTRUE(all.equal(drop(attr(ht, "hatmatrix") %*% cars$dist),
+                            as.vector(predict(cars.gb)))))
> ht25 <- hatvalues(cars.gb[25])
> stopifnot(isTRUE(all.equal(drop(attr(ht25, "hatmatrix") %*% cars$dist),
+                            as.vector(predict(cars.gb[25])))))
> stopifnot(isTRUE(all.equal(drop(attr(ht25, "hatmatrix") %*% cars$dist),
+                            as.vector(fitted(cars.gb[25])))))
> 
> ### check boosting hat matrix with multiple independent variables
> ### and weights
> data("bodyfat", package = "mboost")
> bffm <- DEXfat ~ age + waistcirc + hipcirc + elbowbreadth + kneebreadth +
+       anthro3a + anthro3b + anthro3c + anthro4 - 1
> indep <- names(bodyfat)[names(bodyfat) != "DEXfat"]
> bodyfat[indep] <- lapply(bodyfat[indep], function(x) x - mean(x))
> bf_gam <- gamboost(bffm, data = bodyfat, control = boost_control(mstop = 10), 
+                    weights = runif(nrow(bodyfat)) * 10)
> ### aic <- AIC(bf_gam)
> ht <- hatvalues(bf_gam)
> 
> off <- bf_gam$offset
> u <- bf_gam$ustart
> 
> stopifnot(isTRUE(all.equal(drop(attr(ht, "hatmatrix") %*% u + off),
+                            as.vector(predict(bf_gam)))))
> stopifnot(isTRUE(all.equal(drop(attr(ht, "hatmatrix") %*% u + off),
+                            as.vector(fitted(bf_gam)))))
> 
> 
> ### compare `gamboost' with `lm' in cases where this is actually possible
> set.seed(290875)
> x <- matrix(runif(1000) * 10, ncol = 10)
> xf <- gl(4, nrow(x)/4)
> 
> ### OK, we need to allow for some small differences (larger mstop values
> ### would fix this)
> stopin <- function(x, y) stopifnot(max(abs(x - y)) < 0.1)
> 
> ### univariate linear model
> df <- data.frame(y = 3*x[,2], x = x)
> ga <- gamboost(y ~ x.2 - 1, data = df,
+                control = boost_control(mstop = 500, nu = 1))
> stopin(fitted(lm(y ~ x.2 - 1, data = df)), fitted(ga))
> 
> ### univariate model involving sin transformation
> df <- data.frame(y = sin(x[,1]), x = x)
> ga <- gamboost(y ~ x.1 - 1, data = df, 
+                control = boost_control(mstop = 500, nu = 1))
> stopin(fitted(lm(y ~ sin(x.1) - 1, data = df)), fitted(ga))
> 
> ### bivariate model: linear and sin
> df <- data.frame(y = sin(x[,1]) + 3*x[,2], x = x)
> ga <- gamboost(y ~ x.1 + x.2 - 1, data = df, 
+                control = boost_control(mstop = 500, nu = 1))
> stopin(fitted(lm(y ~ sin(x.1) + x.2 - 1, data = df)), fitted(ga))
> ga <- gamboost(y ~ x.1 + x.2 - 1, data = df, dfbase = c(4, 1), 
+                control = boost_control(mstop = 500, nu = 1))
> stopin(fitted(lm(y ~ sin(x.1) + x.2 - 1, data = df)), fitted(ga))
> 
> ### ANCOVA model
> df <- data.frame(y = 3 * x[,2] + (1:4)[xf], x = x)
> ga <- gamboost(y ~ xf + x.2 - 1, data = df, 
+                control = boost_control(mstop = 500, nu = 1))
> stopin(fitted(lm(y ~ xf + x.2 - 1, data = df)), fitted(ga))
> ga <- gamboost(y ~ xf + sin(x.1) + x.2, data = df, 
+                dfbase = c(1, 1, 4, 1),
+                control = boost_control(mstop = 500, nu = 1))
> stopin(fitted(lm(y ~ xf + sin(x.1) + x.2, data = df)), fitted(ga))
> 
> 
> ### check centering
> y <- rnorm(20)
> xn <- rnorm(20)
> xnm <- xn - mean(xn)
> xf <- gl(2, 10)
> gc <- gamboost(y ~ xn + xf)
> g <- gamboost(y ~ xnm + xf)
> stopifnot(max(abs(fitted(gc) - fitted(g))) < 1 / 10000)
> 
> pc1 <- predict(gc)
> pc2 <- predict(gc, newdata = data.frame(xn = xn, xf = xf))
> pc3 <- predict(g)
> stopifnot(all.equal(pc1, pc2))
> stopifnot(max(abs(pc2 - pc3)) < 1 / 10000)
> 
> ### formula interfaces
> tmp <- data.frame(x1 = runif(100), x2 = runif(100), y = rnorm(100))
> fm1 <- y ~ bss(x1, df = 3) + bss(x2, df = 3)
> fm2 <- y ~ x1 + x2
> mod1 <- gamboost(fm1, data = tmp)
> mod2 <- gamboost(fm2, data = tmp, base = "bss", dfbase = 3)
> stopifnot(max(abs(fitted(mod1) - fitted(mod2))) < .Machine$double.eps)
> stopifnot(max(abs(predict(mod1, newdata = tmp) - predict(mod2, newdata = tmp))) < .Machine$double.eps)
> 
> fm1 <- y ~ bbs(x1, df = 3) + bbs(x2, df = 3)
> fm2 <- y ~ x1 + x2
> mod1 <- gamboost(fm1, data = tmp)
> mod2 <- gamboost(fm2, data = tmp, base = "bbs", dfbase = 3)
> stopifnot(max(abs(fitted(mod1) - fitted(mod2)))  < .Machine$double.eps)
> stopifnot(max(abs(predict(mod1, newdata = tmp) - predict(mod2, newdata = tmp)))  < .Machine$double.eps)
> 
> fm1 <- y ~ bols(x1) + bols(x2)
> fm2 <- y ~ x1 + x2
> mod1 <- gamboost(fm1, data = tmp)
> mod2 <- gamboost(fm2, data = tmp, base = "bols")
> stopifnot(max(abs(fitted(mod1) - fitted(mod2)))  < .Machine$double.eps)
> stopifnot(max(abs(predict(mod1, newdata = tmp) - predict(mod2, newdata = tmp)))  < .Machine$double.eps)
> 
> fm1 <- y ~ btree(x1) + btree(x2)
> fm2 <- y ~ x1 + x2
> mod1 <- gamboost(fm1, data = tmp)
> mod2 <- gamboost(fm2, data = tmp, base = "btree")
> stopifnot(max(abs(fitted(mod1) - fitted(mod2)))  < .Machine$double.eps)
> stopifnot(max(abs(predict(mod1, newdata = tmp) - predict(mod2, newdata = tmp)))  < .Machine$double.eps)
> 
> ## Cox model
> 
> fit2 <- gamboost(Surv(futime, fustat) ~ bbs(age, knots = 40) +
+     bols(resid.ds) + bols(rx) + bols(ecog.ps), data = ovarian, 
+     family = CoxPH(), control = boost_control(mstop = 1000))
> 
> A2 <- survFit(fit2)
> A2
$surv
           [,1]
 [1,] 0.9980873
 [2,] 0.9929781
 [3,] 0.9867334
 [4,] 0.9768941
 [5,] 0.9154316
 [6,] 0.8567420
 [7,] 0.7968431
 [8,] 0.7206421
 [9,] 0.6401860
[10,] 0.5591371
[11,] 0.4453696
[12,] 0.3387993

$time
 [1]  59 115 156 268 329 353 365 431 464 475 563 638

$n.event
 [1] 1 1 1 1 1 1 1 1 1 1 1 1

attr(,"class")
[1] "survFit"
> 
> newdata <- ovarian[c(1,3,12),]
> A2 <- survFit(fit2, newdata = newdata)
> A2
$surv
                  1            3        12
 [1,]  5.342158e-01 8.936563e-01 0.9991571
 [2,]  9.949982e-02 6.611135e-01 0.9969011
 [3,]  1.260646e-02 4.564287e-01 0.9941348
 [4,]  4.734828e-04 2.533792e-01 0.9897562
 [5,]  2.712914e-13 5.576930e-03 0.9618288
 [6,]  1.023472e-22 1.138864e-04 0.9341641
 [7,]  5.035562e-33 1.613980e-06 0.9048128
 [8,]  2.551037e-47 4.408263e-09 0.8656279
 [9,]  3.716160e-64 4.215980e-12 0.8216478
[10,]  2.082241e-83 1.487476e-15 0.7740910
[11,] 9.220061e-116 2.346028e-21 0.7002863
[12,] 1.169240e-154 2.482172e-28 0.6208101

$time
 [1]  59 115 156 268 329 353 365 431 464 475 563 638

$n.event
 [1] 1 1 1 1 1 1 1 1 1 1 1 1

attr(,"class")
[1] "survFit"
> 
> ### gamboost with explicit intercept
> df <- data.frame(x = 1:100, y = rnorm(1:100), int = rep(1, 100))
> mod <- gamboost(y ~ bols(int, center = TRUE) + bols(x, center = TRUE), data = df, 
+                 control = boost_control(mstop = 2500))
> cf <- unlist(coef(mod))
> cf[1] <- cf[1] + mod$offset
> tmp <- max(abs(cf - coef(lm(y ~ x, data = df))))
> stopifnot(tmp < 1e-5)
> tmp <- max(abs(fitted(mod) - fitted(lm(y ~ x, data = df))))
> stopifnot(tmp < 1e-5)
> 
